<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="google-site-verification" content="zOKKIZEh_k3yZ2HWpUHMK1I0bNhnvzIGFRU7A2LpM-k" />
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- SEO优化 1: 优化网页标题，突出核心身份 -->
    <title>Deyu Zhou - AI Researcher | HKUST-GZ</title>
    
    <!-- SEO优化 2: 添加详细的Meta描述，吸引搜索点击 -->
    <meta name="description" content="Personal homepage of Deyu Zhou (周德宇), a Ph.D. candidate at HKUST-GZ, supervised by Prof. Harry Shum. My research focuses on interactive world models, text-to-video generation, and AI for social good.">
    
    <!-- SEO优化 3: 添加Meta关键词，帮助搜索引擎分类 -->
    <meta name="keywords" content="Deyu Zhou, 周德宇, AI Researcher, HKUST-GZ, Interactive World Models, Text-to-Video, Autoregressive Models, Harry Shum, AI for Social Good">

    <!-- SEO优化 4: 添加规范URL，避免重复内容问题 -->
    <link rel="canonical" href="https://your-domain.com/" /> <!-- 请务必将 your-domain.com 替换成你的主页域名 -->

    <style>
        /* 您的所有 CSS 样式都完整保留在此 */
        :root {
            --primary: #2A5C84;
            --accent: #FF6B6B;
            --light: #F8F9FA;
            --dark: #212529;
            --transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; font-family: 'Segoe UI', system-ui, sans-serif; }
        body { background: var(--light); line-height: 1.6; color: var(--dark); }
        .container { max-width: 1200px; margin: 0 auto; padding: 2rem; }
        .profile-header { text-align: center; margin-bottom: 3rem; }
        .profile-content { display: grid; grid-template-columns: 280px 1fr; gap: 3rem; align-items: start; }
        .profile-img { width: 100%; height: 420px; object-fit: cover; border-radius: 16px; box-shadow: 0 8px 24px rgba(0,0,0,0.1); transition: var(--transition); position: sticky; top: 2rem; }
        .profile-img:hover { transform: scale(1.02) rotate(-1deg); box-shadow: 0 12px 32px rgba(0,0,0,0.15); }
        .experience-box { background: white; padding: 2rem; border-radius: 16px; box-shadow: 0 4px 12px rgba(0,0,0,0.08); }
        .collab-grid { display: grid; gap: 1.5rem; margin-top: 1.5rem; }
        .collab-group { display: grid; grid-template-columns: 100px 1fr; gap: 1rem; align-items: start; }
        .collab-links { display: flex; flex-wrap: wrap; gap: 0.8rem; }
        .pub-section { margin-top: 4rem; }
        .pub-card { display: grid; grid-template-columns: 200px 1fr; gap: 2rem; background: white; border-radius: 16px; padding: 2rem; margin: 2rem 0; box-shadow: 0 4px 12px rgba(0,0,0,0.08); transition: var(--transition); }
        .pub-card:hover { transform: translateY(-5px); box-shadow: 0 8px 24px rgba(42, 92, 132, 0.12); }
        .pub-media { width: 100%; height: 150px; border-radius: 8px; background: var(--light); display: flex; align-items: center; justify-content: center; color: var(--primary); }
        .tag { display: inline-block; padding: 0.25rem 0.75rem; border-radius: 20px; background: var(--accent); color: white; font-size: 0.9em; margin: 0 0.5rem 0.5rem 0; transition: var(--transition); }
        a { color: var(--primary); text-decoration: none; position: relative; }
        a::after { content: ''; position: absolute; bottom: -2px; left: 0; width: 0; height: 2px; background: var(--accent); transition: var(--transition); }
        a:hover::after { width: 100%; }
        @media (max-width: 768px) {
            .profile-content { grid-template-columns: 1fr; }
            .profile-img { height: 300px; width: 100%; position: static; }
            .collab-group { grid-template-columns: 1fr; }
            .pub-card { grid-template-columns: 1fr; }
        }
        .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.9); justify-content: center; align-items: center; opacity: 0; transition: opacity 0.3s ease; }
        .modal.show { display: flex; opacity: 1; }
        .modal-content { max-width: 90%; max-height: 90vh; object-fit: contain; transform: scale(0.8); transition: transform 0.3s cubic-bezier(0.4, 0, 0.2, 1); }
        .modal.show .modal-content { transform: scale(1); }
        .close { position: absolute; top: 30px; right: 30px; color: white; font-size: 40px; font-weight: 300; cursor: pointer; transition: transform 0.2s ease; }
        .close:hover { transform: rotate(90deg); }
        #caption { position: absolute; bottom: 20px; color: white; text-align: center; font-size: 1.1em; }
        .acknowledgement a { color: var(--accent); font-weight: 500; white-space: nowrap; }
        .acknowledgement a:hover { text-decoration: underline; text-underline-offset: 2px; }
        @media (max-width: 768px) { .acknowledgement a { white-space: normal; } }
        .ack-card { background: white; border-radius: 16px; padding: 2rem; box-shadow: 0 4px 12px rgba(0,0,0,0.08); margin-bottom: 2rem; }
        .ack-card a { color: var(--accent); font-weight: 500; white-space: nowrap; transition: all 0.2s ease; }
        .ack-card a:hover { text-decoration: underline; text-underline-offset: 3px; }
        @media (max-width: 768px) { .ack-card { padding: 1.5rem; } .ack-card a { white-space: normal; } }
        .profile-summary p { color: var(--secondary-color); line-height: 1.6; font-size: 1.1rem; max-width: 800px; margin: 0 auto 1.5rem auto; }
        .collaborators { font-size: 0.9rem; color: #777; }
    </style>
</head>
<body>
    <div class="container">
        <!-- 主体内容 -->
        <div class="profile-content">
            <!-- 左侧头像 -->
            <!-- SEO优化 5: 为图片添加更具描述性的 alt 文本 -->
            <img src="images/me.jpg" alt="Profile photo of Deyu Zhou, AI Researcher" class="profile-img">
            
            <!-- 右侧经历 -->
            <div class="experience-box">
                <!-- SEO优化 6: 使用 h1 标签作为页面唯一主标题，这是最重要的内容 -->
                <h1>Deyu Zhou 周德宇</h1>
                
                <!-- SEO优化 7: 使用 p 标签来表示段落，而不是 h5 标题标签 -->
                <p><strong>Email:</strong> dzhou861[at]connect.hkust-gz.edu.cn</p>
                <p>I research interactive world models, driven by the lifelong goal of using AI for social good.</p>
                <p>I'm always excited to discuss new ideas, especially the <span class="highlight">crazy</span> ones. Don't hesitate to get in touch!</p>
                <p>Ph.D. candidate @ HKUST-GZ, supervised by 
                    <!-- SEO优化 8: 为外部链接添加安全和SEO友好的属性 -->
                    <a href="https://ias.hkust.edu.hk/people/ias-members/alumni/prof-harry-heung-yeung-shum" target="_blank" rel="noopener noreferrer">Prof. Harry SHUM</a> and 
                    <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/NI-LionelMing-Shuan/ni" target="_blank" rel="noopener noreferrer">Prof. Lionel NI.</a>
                </p>
                
                <div style="margin-top: 2rem; margin-bottom: 2rem;">
                    <div style="background: var(--light); padding: 1.0rem; border-radius: 6px;">
                        <h3 style="color: var(--primary); margin-bottom: 1rem;">Selective Projects</h3>
                        <p style="color: #666; margin: 0.3rem 0;"><strong>Huawei</strong> · Face Blur Detection, Virtual Makeup (2019)</p>
                        <p style="color: #666; margin: 0.3rem 0;"><strong>Tencent AI Lab</strong> · Emotion Classification, Neural Machine Translation (2020-2021)</p>
                        <p style="color: #666; margin: 0.3rem 0;"><strong>Xiaobing</strong> · Multimodal Conversation, Audio-driven Talking Head Generation (2021-2022)</p>
                        <p style="color: #666; margin: 0.3rem 0;"><strong>Step Fun</strong> · Text-to-Video Generation, Autoregressive Video Generation (2024)</p>
                    </div>
                </div>

                <h3 style="color: var(--primary); margin-bottom: 1rem;">Mentors & Collaborators</h3>
                <p class="collaborators">
                    I have been very fortunate to work with and learn from 
                    <a href="http://ieeexplore.ieee.org/author/38231747500" target="_blank" rel="noopener noreferrer">Dr. Chen Dong</a>, 
                    <a href="https://scholar.google.com/citations?user=68mtRggAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Dr. Shuangzhi Wu</a>, 
                    <a href="https://tuzhaopeng.github.io/" target="_blank" rel="noopener noreferrer">Dr. Zhaopeng Tu</a>, 
                    <a href="https://sites.google.com/site/zjuwby/" target="_blank" rel="noopener noreferrer">Dr. Baoyuan Wang</a>, 
                    <a href="https://scholar.google.com/citations?user=hJ-VrrIAAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">Dr. Zheng Ge</a>, 
                    <a href="https://nanduan.github.io/" target="_blank" rel="noopener noreferrer">Dr. Nan Duan</a> and 
                    <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">Dr. Xiangyu Zhang</a>.
                </p>
            </div>
        </div>

        <!-- 论文发表 -->
        <section class="pub-section">
            <h2 style="color: var(--primary); margin-bottom: 2rem;">Research Highlights</h2>

            <div class="pub-card">
                <div class="pub-media">
                    <video autoplay loop muted playsinline 
                           style="width: 100%; height: 100%; object-fit: cover; border-radius: 6px;">
                        <source src="images/NextStep-1.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div>
                    <div class="tags">
                        <span class="tag">Autoregressive Text-to-Image Generation</span>
                        <span class="tag">Open-sourced Foundation Model</span>
                    </div>
                    <h3>NextStep-1 Technical Report</h3>
                    <p class="pub-meta">Technical Report</p>
                    <p class="pub-abstract">
                        Autoregressive text-to-image model with continuous tokens.
                    </p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2508.10711">Paper</a> | 
                        <a href="https://github.com/stepfun-ai/NextStep-1">Code</a> | 
                        <a href="https://stepfun.ai/research/en/nextstep1">Project</a>
                    </div>
                </div>
            </div>
            
            <div class="pub-card">
                <div class="pub-media">
                    <video autoplay loop muted playsinline style="width: 100%; height: 100%; object-fit: cover; border-radius: 6px;">
                        <source src="images/step-t2v.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div>
                    <div class="tags"><span class="tag">30B Text-to-Video Generation</span><span class="tag">Open-sourced Foundation Model</span></div>
                    <h3>Step-Video-T2V Technical Report</h3>
                    <p class="pub-meta">Technical Report</p>
                    <p class="pub-abstract">State-of-the-art text-to-video model with 30B parameters, capable of generating 204-frame videos through novel architecture design.</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2502.10248" target="_blank" rel="noopener noreferrer">Paper</a> | 
                        <a href="https://github.com/stepfun-ai/Step-Video-T2V" target="_blank" rel="noopener noreferrer">Code</a> | 
                        <a href="https://github.com/stepfun-ai/Step-Video-T2V" target="_blank" rel="noopener noreferrer">Project</a>
                    </div>
                </div>
            </div>

            <div class="pub-card">
                <div class="pub-media">
                    <figure style="margin: 0; position: relative;">
                        <img src="images/magi.png" alt="Model architecture diagram for MAGI, an autoregressive video generation framework." style="width: 100%; height: 100%; object-fit: cover; border-radius: 6px;">
                        <figcaption style="position: absolute; bottom: 8px; right: 8px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 4px; font-size: 0.8em;">Model Arch.</figcaption>
                    </figure>
                </div>
                <div>
                    <div class="tags"><span class="tag">Autoregressive Video Generation</span><span class="tag">Novel Foundation Architecture</span></div>
                    <h3>Taming Teacher Forcing for Masked Autoregressive Video Generation</h3>
                    <p class="pub-meta">CVPR 2025</p>
                    <p class="pub-abstract">A novel frame-level autoregressive video generation framework combining masked and causal modeling with Complete Teacher Forcing, achieving +23% FVD improvement.</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2501.12389" target="_blank" rel="noopener noreferrer">Paper</a> | 
                        <a href="https://magivideogen.github.io/" target="_blank" rel="noopener noreferrer">Code</a> | 
                        <a href="https://magivideogen.github.io/" target="_blank" rel="noopener noreferrer">Project</a>
                    </div>
                </div>
            </div>

            <div class="pub-card">
                <div class="pub-media">
                    <figure style="margin: 0; position: relative;">
                        <img src="images/thpad.png" alt="Visual results of TH-PAD, a talking head generation model with diffusion priors." style="width: 100%; height: 100%; object-fit: cover; border-radius: 6px;">
                    </figure>
                </div>
                <div>
                    <div class="tags"><span class="tag">Talking Head Generation</span><span class="tag">Diffusion Prior</span></div>
                    <h3>TH-PAD: Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors</h3>
                    <p class="pub-meta">ICCV 2023</p>
                    <p class="pub-abstract">We introduce a novel framework for one-shot audio-driven talking head generation. Unlike prior works that require additional driving sources for controlled synthesis in a deterministic manner, we instead sample all holistic lip-irrelevant facial motions (i.e. pose, expression, blink, gaze, etc.) to semantically match the input audio while still maintaining both the photo-realism of audio-lip synchronization and overall naturalness.</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2212.04248" target="_blank" rel="noopener noreferrer">Paper</a> | 
                        <a href="https://zxyin.github.io/TH-PAD/" target="_blank" rel="noopener noreferrer">Project</a>
                    </div>
                </div>
            </div>
        </section>
    </div>

    <!-- 模态框 (您的原始代码，功能完好) -->
    <div id="imageModal" class="modal">
        <span class="close">&times;</span>
        <img class="modal-content" id="expandedImg">
        <div id="caption"></div>
    </div>

    <!-- 脚本 (您的原始代码，功能完好) -->
    <script>
        document.querySelectorAll('figure').forEach(figure => {
            figure.style.cursor = 'zoom-in';
            figure.addEventListener('click', function(e) {
                e.stopPropagation();
                const modal = document.getElementById('imageModal');
                const modalImg = document.getElementById("expandedImg");
                const captionText = document.getElementById("caption");
                const img = this.querySelector('img');
                modalImg.src = img.src;
                captionText.innerHTML = img.alt;
                modal.classList.add('show');
                if(this.querySelector('video')) {
                    const video = this.querySelector('video').cloneNode(true);
                    video.controls = true;
                    modalImg.replaceWith(video);
                }
            });
        });
        const modal = document.getElementById('imageModal');
        document.querySelector('.close').onclick = () => modal.classList.remove('show');
        window.onclick = (e) => { if(e.target === modal) modal.classList.remove('show'); }
        document.addEventListener('keydown', (e) => { if(e.key === 'Escape') modal.classList.remove('show'); });
    </script>
</body>
</html>
